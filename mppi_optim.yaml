program: mppi_with_model.py
method: bayes
metric:
  goal: maximize
  name: total_reward
parameters:
  mppi_roll_outs:
    # distribution: log_uniform
    # # min: 0.0
    # # max: 1.0
    # # q: 1
    values: [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,262144]
  mppi_time_steps:
    # distribution: q_log_uniform
    # min: 1
    # max: 6
    # q: 1
    values: [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,262144]
  mppi_lambda:
    # distribution: q_log_uniform
    # min: -3
    # max: 2
    # q: 0.0001
    values: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
  mppi_sigma:
    # distribution: q_log_uniform
    # min: -3
    # max: 2
    # q: 0.0001
    values: [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 0.8, 1.0, 1.5, 2.0, 10.0, 100.0, 1000.0]
  
early_terminate:
  type: hyperband
  s: 2
  eta: 3
  max_iter: 27